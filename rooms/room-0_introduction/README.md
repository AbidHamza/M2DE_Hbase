# Room 0 : Introduction √† l'environnement

##  Objectifs de cette room

√Ä la fin de cette room, vous saurez :
-  V√©rifier que votre environnement fonctionne
-  Utiliser les commandes de base de HDFS, HBase et Hive
-  Comprendre ce que fait chaque commande
-  Cr√©er vos premiers fichiers et tables

** Temps estim√© :** 1-2 heures (prenez votre temps !)

---

##  Rappels th√©oriques

### Qu'est-ce que Hadoop ?

**Hadoop** est comme une **√©norme biblioth√®que** pour stocker et traiter des donn√©es tr√®s volumineuses.

Imaginez que vous avez des millions de livres. Au lieu de les mettre dans une seule biblioth√®que (qui serait trop petite), vous les r√©partissez dans plusieurs biblioth√®ques. C'est ce que fait Hadoop !

**Les 3 composants principaux :**

1. **HDFS (Hadoop Distributed File System)**
   - C'est le **syst√®me de fichiers** distribu√©
   - Comme le disque dur de votre ordinateur, mais r√©parti sur plusieurs machines
   - **R√¥le :** Stocker les fichiers de donn√©es

2. **YARN (Yet Another Resource Negotiator)**
   - C'est le **gestionnaire de ressources**
   - Comme un chef d'orchestre qui organise qui fait quoi
   - **R√¥le :** Organiser le traitement des donn√©es

3. **MapReduce**
   - C'est une **m√©thode de traitement** des donn√©es
   - Divise le travail en petites t√¢ches, les ex√©cute en parall√®le, puis combine les r√©sultats
   - **R√¥le :** Traiter les donn√©es efficacement

### Qu'est-ce que HBase ?

**HBase** est une **base de donn√©es** sp√©ciale qui fonctionne sur Hadoop.

**Analogie simple :** 
- Une base de donn√©es normale (comme MySQL) = un classeur avec des feuilles organis√©es
- HBase = un classeur G√âANT qui peut contenir des milliards de feuilles, et o√π vous pouvez trouver n'importe quelle feuille tr√®s rapidement

**Caract√©ristiques principales :**
-  Stocke des **tr√®s grandes quantit√©s** de donn√©es (milliards de lignes)
-  Acc√®s **tr√®s rapide** aux donn√©es (m√™me dans une table √©norme)
-  **Scalable** : peut grandir ind√©finiment en ajoutant des machines
-  **NoSQL** : pas besoin de d√©finir un sch√©ma rigide au d√©part

**Quand l'utiliser ?**
- Donn√©es qui changent souvent (ex: logs en temps r√©el)
- Besoin d'acc√®s rapide √† des donn√©es sp√©cifiques
- Volumes de donn√©es tr√®s importants

### Qu'est-ce que Hive ?

**Hive** est un **entrep√¥t de donn√©es** qui permet d'utiliser du **SQL** sur Hadoop.

**Analogie simple :**
- HDFS = un entrep√¥t g√©ant plein de bo√Ætes (fichiers)
- Hive = un syst√®me qui vous permet de poser des questions en SQL sur ces bo√Ætes
- Au lieu de chercher manuellement, vous dites "donne-moi toutes les bo√Ætes rouges" en SQL

**Caract√©ristiques principales :**
-  Utilise **HiveQL** (un langage tr√®s proche de SQL)
-  Parfait pour **l'analyse** de donn√©es
-  Permet de faire des **requ√™tes complexes** (jointures, agr√©gations)
-  Compatible avec les outils **BI** (Business Intelligence)

**Quand l'utiliser ?**
- Analyse de donn√©es historiques
- Requ√™tes complexes avec jointures
- Int√©gration avec des outils de reporting
- Traitement par lots (batch)

---

##  Mise en route - √âtape par √©tape

### √âtape 1 : V√©rifier que Docker fonctionne

**Avant de commencer, v√©rifions que tout est pr√™t !**

**1. Ouvrez votre terminal**

**2. V√©rifiez que vous √™tes dans le bon dossier**

```bash
pwd
```

**Explication :**
- `pwd` = "print working directory" (afficher le dossier actuel)
- Vous devriez voir quelque chose comme `/chemin/vers/M2DE_Hbase`

**Si vous n'√™tes pas dans le bon dossier :**
```bash
cd M2DE_Hbase
```

**3. V√©rifiez l'√©tat des conteneurs**

```bash
docker-compose ps
```

**Explication d√©taill√©e :**
- `docker-compose` = programme qui g√®re plusieurs conteneurs ensemble
- `ps` = "process status" (√©tat des processus)
- Cette commande montre tous vos conteneurs et leur √©tat

**R√©sultat attendu :**

Vous devriez voir quelque chose comme :
```
NAME                              STATUS
hbase-hive-learning-lab-hadoop-1   Up
hbase-hive-learning-lab-hbase-1    Up
hbase-hive-learning-lab-hive-1     Up
...
```

** Si tous sont "Up"** ‚Üí Parfait ! Passez √† l'√©tape suivante.

** Si certains sont "Exited" ou "Restarting"** ‚Üí Il y a un probl√®me. Regardez les logs :
```bash
docker-compose logs
```

---

### √âtape 2 : Tester HDFS (Hadoop) - EXPLICATION D√âTAILL√âE

**HDFS est le syst√®me de fichiers de Hadoop. Testons-le !**

#### 2.1 Entrer dans le conteneur Hadoop

**Commande :**
```bash
docker exec -it hbase-hive-learning-lab-hadoop-1 bash
```

**Explication MOT PAR MOT :**
- `docker` = le programme Docker
- `exec` = ex√©cuter une commande dans un conteneur
- `-it` = deux options combin√©es :
  - `-i` = mode interactif (vous pouvez taper)
  - `-t` = terminal (affichage format√©)
- `hbase-hive-learning-lab-hadoop-1` = le nom exact du conteneur Hadoop
- `bash` = le programme √† lancer (un shell Linux)

**Ce qui se passe :**
1. Docker trouve le conteneur nomm√© `hbase-hive-learning-lab-hadoop-1`
2. Il lance un shell `bash` √† l'int√©rieur
3. Vous √™tes maintenant "connect√©" au conteneur

**R√©sultat :** Votre prompt change ! Vous voyez quelque chose comme :
```
root@hadoop:/#
```

** Vous √™tes maintenant DANS le conteneur Hadoop !**

#### 2.2 V√©rifier que HDFS fonctionne

**Une fois dans le conteneur, tapez :**

```bash
hdfs dfsadmin -report
```

**Explication d√©taill√©e :**
- `hdfs` = le programme Hadoop pour le syst√®me de fichiers
- `dfsadmin` = commande d'administration de HDFS
- `-report` = option pour obtenir un rapport

**Ce que fait cette commande :**
Elle affiche des informations sur l'√©tat de HDFS :
- Nombre de DataNodes (machines qui stockent les donn√©es)
- Espace disque disponible
- Espace disque utilis√©
- √âtat de sant√© du syst√®me

**R√©sultat attendu :**

Vous devriez voir quelque chose comme :
```
Configured Capacity: ...
Present Capacity: ...
DFS Used: ...
DFS Remaining: ...
Live datanodes (1): ...
```

** Si vous voyez ces informations** ‚Üí HDFS fonctionne !

#### 2.3 Lister les fichiers dans HDFS

**Commande :**
```bash
hdfs dfs -ls /
```

**Explication d√©taill√©e :**
- `hdfs dfs` = commandes pour manipuler les fichiers dans HDFS
- `-ls` = "list" (lister les fichiers)
- `/` = la racine du syst√®me de fichiers HDFS (comme `C:\` sur Windows)

**Ce que fait cette commande :**
Elle liste tous les fichiers et dossiers √† la racine de HDFS.

**R√©sultat attendu :**

Au d√©but, vous pourriez voir :
```
drwxr-xr-x   - root supergroup          0 2024-01-01 10:00 /tmp
```

Ou une liste vide, ou d'autres dossiers.

**D√©codage du r√©sultat :**
- `drwxr-xr-x` = permissions (d = dossier, rwx = lire/√©crire/ex√©cuter)
- `root` = propri√©taire
- `supergroup` = groupe
- `0` = taille (0 pour un dossier)
- Date et heure de cr√©ation
- Nom du dossier/fichier

#### 2.4 Cr√©er un dossier de test

**Cr√©ons un dossier pour tester :**

```bash
hdfs dfs -mkdir /test
```

**Explication :**
- `-mkdir` = "make directory" (cr√©er un dossier)
- `/test` = le nom du dossier √† cr√©er

**V√©rifions qu'il a √©t√© cr√©√© :**

```bash
hdfs dfs -ls /
```

**R√©sultat attendu :** Vous devriez maintenant voir `/test` dans la liste !

#### 2.5 Sortir du conteneur

**Quand vous avez fini avec HDFS :**

```bash
exit
```

**Explication :** Cette commande vous fait quitter le conteneur et revenir √† votre terminal normal.

**R√©sultat :** Votre prompt redevient normal.

---

### √âtape 3 : Tester HBase - EXPLICATION D√âTAILL√âE

**HBase est une base de donn√©es NoSQL. Testons-la !**

#### 3.1 Entrer dans le shell HBase

**Commande :**
```bash
docker exec -it hbase-hive-learning-lab-hbase-1 hbase shell
```

**Explication :**
- M√™me principe que pour Hadoop
- `hbase shell` = lance le shell interactif de HBase (un programme sp√©cial pour HBase)

**R√©sultat :** Vous voyez un prompt sp√©cial :
```
HBase Shell
Use "help" to get list of supported commands.
Use "exit" to quit this shell.
Version 2.5.0, ...

hbase(main):001:0>
```

** Vous √™tes maintenant dans le shell HBase !**

**Note :** Le prompt `hbase(main):001:0>` signifie :
- `hbase` = vous √™tes dans HBase
- `main` = contexte principal
- `001` = num√©ro de la commande
- `0` = num√©ro de la ligne

#### 3.2 V√©rifier la version de HBase

**Commande :**
```hbase
version
```

**Explication :**
- `version` = commande simple qui affiche la version install√©e
- ** IMPORTANT :** Pas de guillemets, pas de point-virgule, juste le mot `version`

**R√©sultat attendu :**

```
2.5.0, r...
```

** Vous voyez la version** ‚Üí HBase fonctionne !

#### 3.3 V√©rifier le statut de HBase

**Commande :**
```hbase
status
```

**Explication :**
- `status` = affiche l'√©tat g√©n√©ral de HBase
- Montre combien de RegionServers sont actifs, combien de tables existent, etc.

**R√©sultat attendu :**

Vous verrez quelque chose comme :
```
1 active master, 0 backup masters, 1 servers, 0 dead, ...
```

**D√©codage :**
- `active master` = le serveur principal fonctionne
- `servers` = nombre de RegionServers (servent les donn√©es)
- `dead` = serveurs qui ne fonctionnent pas (devrait √™tre 0)

** Si vous voyez "1 active master"** ‚Üí HBase fonctionne correctement !

#### 3.4 Lister les tables existantes

**Commande :**
```hbase
list
```

**Explication :**
- `list` = liste toutes les tables dans HBase
- Au d√©but, il n'y en a probablement aucune

**R√©sultat attendu :**

Au d√©but :
```
TABLE
0 row(s) in 0.1234 seconds
```

Cela signifie : "0 tables trouv√©es"

** C'est normal au d√©but !** Vous cr√©erez vos premi√®res tables dans les exercices.

#### 3.5 Obtenir de l'aide

**Si vous √™tes perdu, demandez de l'aide :**

```hbase
help
```

**R√©sultat :** Liste de toutes les commandes disponibles avec leur description.

**Pour l'aide sur une commande sp√©cifique :**

```hbase
help 'create'
```

**Explication :** Affiche l'aide d√©taill√©e sur la commande `create`.

#### 3.6 Sortir du shell HBase

**Quand vous avez fini :**

```hbase
exit
```

**Explication :** Quitte le shell HBase et revient √† votre terminal.

**R√©sultat :** Vous revenez √† votre terminal normal.

---

### √âtape 4 : Tester Hive - EXPLICATION D√âTAILL√âE

**Hive permet d'utiliser SQL sur Hadoop. Testons-le !**

#### 4.1 Entrer dans Hive

**Commande :**
```bash
docker exec -it hbase-hive-learning-lab-hive-1 hive
```

**Explication :**
- M√™me principe que pour HBase
- `hive` = lance le CLI (Command Line Interface) de Hive

**R√©sultat :** Vous voyez un prompt Hive :

```
Logging initialized using configuration in ...
Hive Session ID = ...
hive>
```

** Vous √™tes maintenant dans Hive !**

#### 4.2 Lister les bases de donn√©es

**Commande :**
```sql
SHOW DATABASES;
```

** ATTENTION TR√àS IMPORTANTE :**
- **Point-virgule `;` OBLIGATOIRE** √† la fin de chaque commande SQL !
- En Hive, toutes les commandes SQL se terminent par `;`
- Si vous oubliez le `;`, Hive attendra que vous le tapiez

**Explication d√©taill√©e :**
- `SHOW` = afficher
- `DATABASES` = les bases de donn√©es
- `;` = fin de la commande (OBLIGATOIRE !)

**R√©sultat attendu :**

```
OK
default
Time taken: 0.123 seconds, Fetched: 1 row(s)
```

**D√©codage :**
- `OK` = la commande a r√©ussi
- `default` = nom de la base de donn√©es par d√©faut (elle existe toujours)
- `Time taken` = temps d'ex√©cution
- `Fetched: 1 row(s)` = 1 ligne retourn√©e (1 base de donn√©es)

** Si vous voyez "default"** ‚Üí Hive fonctionne !

#### 4.3 Utiliser la base de donn√©es par d√©faut

**Commande :**
```sql
USE default;
```

**Explication :**
- `USE` = utiliser/s√©lectionner
- `default` = nom de la base de donn√©es
- `;` = fin de commande

**Ce que fait cette commande :**
Elle s√©lectionne la base de donn√©es `default` comme base de travail. Toutes les commandes suivantes s'appliqueront √† cette base.

**R√©sultat attendu :**

```
OK
Time taken: 0.045 seconds
```

#### 4.4 Lister les tables

**Commande :**
```sql
SHOW TABLES;
```

**Explication :**
- `SHOW TABLES` = afficher les tables
- Au d√©but, il n'y en a probablement aucune

**R√©sultat attendu :**

```
OK
Time taken: 0.123 seconds
```

(Aucune table list√©e, c'est normal !)

#### 4.5 Obtenir de l'aide

**Pour voir toutes les commandes disponibles :**

```sql
SHOW FUNCTIONS;
```

**R√©sultat :** Liste de toutes les fonctions disponibles (SUM, COUNT, AVG, etc.)

#### 4.6 Sortir de Hive

**Quand vous avez fini :**

```sql
exit;
```

** N'oubliez pas le point-virgule !**

**R√©sultat :** Vous revenez √† votre terminal.

---

##  Exercices pratiques - GUIDE PAS √Ä PAS

### Exercice 1 : Exploration HDFS

**Objectif :** Cr√©er des dossiers et copier des fichiers dans HDFS

#### √âtape 1.1 : Entrer dans le conteneur Hadoop

```bash
docker exec -it hbase-hive-learning-lab-hadoop-1 bash
```

** Vous √™tes dans le conteneur quand votre prompt change.**

#### √âtape 1.2 : Cr√©er un dossier de test

```bash
hdfs dfs -mkdir /data/test
```

**Explication :**
- `/data/test` = le chemin complet du dossier √† cr√©er
- `/data` = dossier parent
- `test` = sous-dossier

**Si le dossier parent n'existe pas, cr√©ez-le d'abord :**

```bash
hdfs dfs -mkdir -p /data/test
```

**Explication de `-p` :**
- `-p` = cr√©er les dossiers parents si n√©cessaire
- Si `/data` n'existe pas, il sera cr√©√© automatiquement

#### √âtape 1.3 : V√©rifier que le dossier existe

```bash
hdfs dfs -ls /data
```

**R√©sultat attendu :** Vous devriez voir `test` dans la liste.

#### √âtape 1.4 : Cr√©er un fichier local de test

**Cr√©ons un fichier texte simple :**

```bash
echo "Ceci est un test" > /tmp/test.txt
```

**Explication :**
- `echo` = affiche du texte
- `>` = redirige la sortie vers un fichier
- `/tmp/test.txt` = le fichier √† cr√©er

**V√©rifions le contenu :**

```bash
cat /tmp/test.txt
```

**R√©sultat attendu :** `Ceci est un test`

#### √âtape 1.5 : Copier le fichier dans HDFS

```bash
hdfs dfs -put /tmp/test.txt /data/test/
```

**Explication d√©taill√©e :**
- `-put` = commande pour uploader/copier un fichier
- `/tmp/test.txt` = fichier source (sur le conteneur)
- `/data/test/` = destination dans HDFS

**Ce qui se passe :**
Le fichier est copi√© du syst√®me de fichiers local vers HDFS.

#### √âtape 1.6 : V√©rifier que le fichier est dans HDFS

```bash
hdfs dfs -ls /data/test/
```

**R√©sultat attendu :** Vous devriez voir `test.txt` dans la liste.

**Voir le contenu du fichier dans HDFS :**

```bash
hdfs dfs -cat /data/test/test.txt
```

**R√©sultat attendu :** `Ceci est un test`

#### √âtape 1.7 : Sortir du conteneur

```bash
exit
```

** Exercice 1 termin√© !**

---

### Exercice 2 : Premi√®re table HBase

**Objectif :** Cr√©er une table, ins√©rer des donn√©es, les lire

#### √âtape 2.1 : Entrer dans le shell HBase

```bash
docker exec -it hbase-hive-learning-lab-hbase-1 hbase shell
```

** Vous voyez le prompt `hbase(main):001:0>`**

#### √âtape 2.2 : Cr√©er une table

**Commande :**
```hbase
create 'test_table', 'info'
```

**Explication D√âTAILL√âE :**
- `create` = commande pour cr√©er une table
- `'test_table'` = nom de la table (entre guillemets simples)
- `'info'` = nom d'une **famille de colonnes**

**Qu'est-ce qu'une famille de colonnes ?**
- En HBase, les colonnes sont organis√©es en **familles**
- C'est comme des dossiers qui regroupent des colonnes li√©es
- Exemple : famille `info` peut contenir `info:name`, `info:age`, `info:city`
- La syntaxe est `FAMILLE:COLONNE`

**R√©sultat attendu :**

```
0 row(s) in 1.2345 seconds

=> Hbase::Table - test_table
```

** Table cr√©√©e avec succ√®s !**

#### √âtape 2.3 : V√©rifier la structure de la table

```hbase
describe 'test_table'
```

**Explication :**
- `describe` = affiche la description/structure
- `'test_table'` = nom de la table

**R√©sultat attendu :**

Vous verrez la structure de la table avec :
- Le nom de la famille de colonnes (`info`)
- Les propri√©t√©s (VERSIONS, TTL, etc.)

#### √âtape 2.4 : Ins√©rer des donn√©es

**Ins√©rons une ligne avec plusieurs colonnes :**

```hbase
put 'test_table', 'row1', 'info:name', 'Test'
```

**Explication MOT PAR MOT :**
- `put` = commande pour ins√©rer/mettre √† jour une valeur
- `'test_table'` = nom de la table
- `'row1'` = **row key** (cl√© de la ligne, identifiant unique)
- `'info:name'` = nom de la colonne (famille `info` + colonne `name`)
- `'Test'` = la valeur √† stocker

**Ins√©rons une autre colonne pour la m√™me ligne :**

```hbase
put 'test_table', 'row1', 'info:age', '25'
```

**Explication :**
- M√™me row key `'row1'` (m√™me ligne)
- Colonne diff√©rente `'info:age'`
- Valeur `'25'`

** Maintenant la ligne `row1` a deux colonnes : `info:name` et `info:age`**

#### √âtape 2.5 : Voir toutes les donn√©es (SCAN)

```hbase
scan 'test_table'
```

**Explication :**
- `scan` = parcourir toutes les lignes d'une table
- `'test_table'` = nom de la table

**R√©sultat attendu :**

```
ROW                    COLUMN+CELL
 row1                  column=info:age, timestamp=..., value=25
 row1                  column=info:name, timestamp=..., value=Test
1 row(s) in 0.1234 seconds
```

**D√©codage :**
- `ROW` = la row key
- `COLUMN+CELL` = la colonne et sa valeur
- `timestamp` = horodatage automatique de chaque modification
- `value` = la valeur stock√©e

** Vous voyez vos donn√©es !**

#### √âtape 2.6 : R√©cup√©rer une ligne sp√©cifique (GET)

```hbase
get 'test_table', 'row1'
```

**Explication :**
- `get` = r√©cup√©rer une ligne sp√©cifique
- `'test_table'` = nom de la table
- `'row1'` = la row key de la ligne √† r√©cup√©rer

**R√©sultat attendu :**

M√™me r√©sultat que `scan`, mais seulement pour la ligne `row1`.

**R√©cup√©rer une colonne sp√©cifique :**

```hbase
get 'test_table', 'row1', {COLUMN => 'info:name'}
```

**Explication :**
- `{COLUMN => 'info:name'}` = filtre pour ne r√©cup√©rer que cette colonne
- Syntaxe sp√©ciale HBase avec accolades et `=>`

**R√©sultat attendu :** Seulement la colonne `info:name` de la ligne `row1`.

#### √âtape 2.7 : Sortir du shell HBase

```hbase
exit
```

** Exercice 2 termin√© !**

---

### Exercice 3 : Premi√®re base de donn√©es Hive

**Objectif :** Cr√©er une base de donn√©es, l'utiliser, la supprimer

#### √âtape 3.1 : Entrer dans Hive

```bash
docker exec -it hbase-hive-learning-lab-hive-1 hive
```

** Vous voyez le prompt `hive>`**

#### √âtape 3.2 : Cr√©er une base de donn√©es

```sql
CREATE DATABASE test_db;
```

**Explication d√©taill√©e :**
- `CREATE DATABASE` = commande SQL pour cr√©er une base de donn√©es
- `test_db` = nom de la base de donn√©es
- `;` = **OBLIGATOIRE** √† la fin !

**R√©sultat attendu :**

```
OK
Time taken: 0.123 seconds
```

** Base de donn√©es cr√©√©e !**

#### √âtape 3.3 : Utiliser cette base de donn√©es

```sql
USE test_db;
```

**Explication :**
- `USE` = s√©lectionner une base de donn√©es
- `test_db` = nom de la base
- Toutes les commandes suivantes s'appliqueront √† cette base

**R√©sultat attendu :**

```
OK
Time taken: 0.045 seconds
```

#### √âtape 3.4 : Lister les tables

```sql
SHOW TABLES;
```

**Explication :**
- `SHOW TABLES` = afficher les tables de la base actuelle
- Au d√©but, elle devrait √™tre vide

**R√©sultat attendu :**

```
OK
Time taken: 0.123 seconds
```

(Aucune table, c'est normal !)

#### √âtape 3.5 : V√©rifier que vous √™tes dans la bonne base

```sql
SELECT current_database();
```

**R√©sultat attendu :** `test_db`

#### √âtape 3.6 : Supprimer la base de donn√©es

** ATTENTION :** La base doit √™tre vide (pas de tables) !

```sql
DROP DATABASE test_db;
```

**Explication :**
- `DROP DATABASE` = supprimer une base de donn√©es
- `test_db` = nom de la base √† supprimer

**R√©sultat attendu :**

```
OK
Time taken: 0.123 seconds
```

**V√©rifions qu'elle n'existe plus :**

```sql
SHOW DATABASES;
```

**R√©sultat attendu :** `test_db` ne devrait plus appara√Ætre (seulement `default`).

#### √âtape 3.7 : Sortir de Hive

```sql
exit;
```

** N'oubliez pas le point-virgule !**

** Exercice 3 termin√© !**

---

##  Fichiers √† compl√©ter

**Cr√©ez un fichier `room-0_exercices.md` dans ce dossier** (`rooms/room-0_introduction/`)

**Structure sugg√©r√©e :**

```markdown
# Room 0 - Mes exercices

## Exercice 1 : Exploration HDFS

### Commandes ex√©cut√©es :
1. `hdfs dfs -mkdir /data/test`
   - **Explication :** Cr√©ation d'un dossier de test
   - **R√©sultat :** Dossier cr√©√© avec succ√®s

2. `hdfs dfs -put /tmp/test.txt /data/test/`
   - **Explication :** Copie d'un fichier dans HDFS
   - **R√©sultat :** Fichier copi√©

### Difficult√©s rencontr√©es :
- Aucune

### Observations :
- HDFS fonctionne correctement
- Les commandes sont simples √† utiliser

## Exercice 2 : Premi√®re table HBase

### Commandes ex√©cut√©es :
1. `create 'test_table', 'info'`
   - **Explication :** Cr√©ation d'une table avec une famille de colonnes
   - **R√©sultat :** Table cr√©√©e

2. `put 'test_table', 'row1', 'info:name', 'Test'`
   - **Explication :** Insertion d'une valeur
   - **R√©sultat :** Donn√©e ins√©r√©e

### Difficult√©s rencontr√©es :
- J'ai oubli√© les guillemets au d√©but
- J'ai compris que la syntaxe est `FAMILLE:COLONNE`

### Observations :
- HBase est tr√®s diff√©rent d'une base SQL classique
- Les row keys sont importantes

## Exercice 3 : Premi√®re base de donn√©es Hive

### Commandes ex√©cut√©es :
1. `CREATE DATABASE test_db;`
   - **Explication :** Cr√©ation d'une base de donn√©es
   - **R√©sultat :** Base cr√©√©e

### Difficult√©s rencontr√©es :
- J'ai oubli√© le point-virgule plusieurs fois
- Hive m'a rappel√© de le mettre

### Observations :
- Hive utilise du SQL, c'est plus familier
- Le point-virgule est obligatoire

## Conclusion

J'ai r√©ussi √† :
-  Utiliser HDFS pour stocker des fichiers
-  Cr√©er une table HBase et y ins√©rer des donn√©es
-  Cr√©er une base de donn√©es Hive

Je suis pr√™t pour la Room 1 !
```

---

##  Validation

**Vous avez termin√© cette room quand :**

- [ ]  Tous les services Docker sont op√©rationnels (v√©rifi√© avec `docker-compose ps`)
- [ ]  Vous avez cr√©√© un dossier dans HDFS et copi√© un fichier
- [ ]  Vous avez cr√©√© une table HBase (`test_table`) avec la famille `info`
- [ ]  Vous avez ins√©r√© au moins 2 colonnes dans cette table
- [ ]  Vous avez utilis√© `scan` et `get` pour voir vos donn√©es
- [ ]  Vous avez cr√©√© une base de donn√©es Hive (`test_db`)
- [ ]  Vous avez utilis√© `USE` pour s√©lectionner cette base
- [ ]  Vous avez supprim√© la base de donn√©es
- [ ]  Vous avez cr√©√© le fichier `room-0_exercices.md` avec toutes vos notes

**Si toutes les cases sont coch√©es ‚Üí F√©licitations ! üéâ**

---

##  Prochaine √©tape

Une fois cette room termin√©e, vous pouvez passer √† **Room 1 : Les bases de HBase**.

Dans la Room 1, vous apprendrez :
- Comment structurer vos donn√©es HBase efficacement
- Les op√©rations CRUD compl√®tes
- Comment travailler avec plusieurs tables
- Les bonnes pratiques

**Bon courage ! **

---

##  Aide m√©moire rapide

### Commandes HDFS
- `hdfs dfs -ls /` = lister
- `hdfs dfs -mkdir /dossier` = cr√©er dossier
- `hdfs dfs -put fichier /destination` = copier fichier
- `hdfs dfs -cat /fichier` = voir contenu

### Commandes HBase
- `create 'table', 'famille'` = cr√©er table
- `put 'table', 'row', 'colonne', 'valeur'` = ins√©rer
- `scan 'table'` = voir tout
- `get 'table', 'row'` = voir une ligne
- `exit` = quitter

### Commandes Hive
- `SHOW DATABASES;` = lister bases
- `CREATE DATABASE nom;` = cr√©er base
- `USE nom;` = utiliser base
- `SHOW TABLES;` = lister tables
- `exit;` = quitter (avec `;` !)

**Gardez ce fichier ouvert pendant vos exercices ! **
